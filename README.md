<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a name="readme-top"></a>

<!-- PROJECT LOGO -->
<br />

<h3 align="center">Material Morphing Toolkit</h3>

  <p align="center">
    Chenxi Liao, Masataka Sawayama, Bei Xiao
  </p>

</div>


This Toolkit allows the user the create material morphing sequences for psychophysical experiments. 

<p align="right">(<a href="#readme-top">back to top</a>)</p>

## Preprint
[Liao, C., Sawayama, M., & Xiao, B. (2024). Probing the Link Between Vision and Language in Material Perception. bioRxiv, 2024-01.](https://www.biorxiv.org/content/10.1101/2024.01.25.577219v2)


<!-- GETTING STARTED -->
## Pre-selected Materials
* We provided samples from three material categories: Soap, Rock and Squishy Toys. The images cover two major lightings: Low and Strong indoor lighting. 

* You can find the generated [Materials from W latent sapce](material_latent_code_W).
  - Soap: soap_strong (soap_strong_30img.npy), soap_low (soap_low_30img.npy)
  - Rock: rock_strong (rock_strong_30img.npy), rock_low (rock_low_30img.npy)
  - Squishy toy: toy_strong (toy_low_30img.npy), toy_low (toy_strong_30img.npy)
  
## Cross-material Morphing
* A sample morphing sequence from [Rock to Squishy Toy](morphing_sequence/rock0_to_toy12_low): A Rock (e.g., rock0) is gradually transformed into a Squishy Toy (e.g., toy12) with 41 linear interpolation steps. 

<p align="right">(<a href="#readme-top">back to top</a>)</p>

